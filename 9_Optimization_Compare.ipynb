{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "9 Optimization Compare",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/TemiLee/TemiLee.github.io/blob/master/9_Optimization_Compare.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "wsZaSsjy757V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2687
        },
        "outputId": "503f0517-379a-4440-dae2-14f8d74b2965"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np,sys\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "np.random.seed(678)\n",
        "\n",
        "def log(x):\n",
        "    return 1 / (1 + np.exp(-1 * x))\n",
        "def d_log(x):\n",
        "    return log(x) * ( 1 - log(x))\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "def d_tanh(x):\n",
        "    return 1 - np.tanh(x) ** 2 \n",
        "\n",
        "def ReLu(x):\n",
        "    mask = (x > 0.0) * 1.0\n",
        "    return x * mask\n",
        "def d_ReLu(x):\n",
        "    mask = (x > 0.0) * 1.0\n",
        "    return mask    \n",
        "\n",
        "def elu(matrix):\n",
        "    mask = (matrix<=0) * 1.0\n",
        "    less_zero = matrix * mask\n",
        "    safe =  (matrix>0) * 1.0\n",
        "    greater_zero = matrix * safe\n",
        "    final = 3.0 * (np.exp(less_zero) - 1) * less_zero\n",
        "    return greater_zero + final\n",
        "def d_elu(matrix):\n",
        "    safe = (matrix>0) * 1.0\n",
        "    mask2 = (matrix<=0) * 1.0\n",
        "    temp = matrix * mask2\n",
        "    final = (3.0 * np.exp(temp))*mask2\n",
        "    return (matrix * safe) + final\n",
        "\n",
        "\n",
        "# 0. Declare Training Data and Labels\n",
        "mnist = input_data.read_data_sets(\"../MNIST_data/\", one_hot=False)\n",
        "train = mnist.test\n",
        "images, labels = train.images, train.labels\n",
        "only_zero_index,only_one_index = np.where(labels==0)[0],np.where(labels==1)[0]\n",
        "only_zero_image,only_zero_label = images[[only_zero_index]],np.expand_dims(labels[[only_zero_index]],axis=1)\n",
        "only_one_image,only_one_label   = images[[only_one_index]],np.expand_dims(labels[[only_one_index]],axis=1)\n",
        "\n",
        "images = np.vstack((only_zero_image,only_one_image))\n",
        "labels = np.vstack((only_zero_label,only_one_label))\n",
        "images,label = shuffle(images,labels)\n",
        "\n",
        "test_image_num,training_image_num = 20,50\n",
        "testing_images, testing_lables =images[:test_image_num,:],label[:test_image_num,:]\n",
        "training_images,training_lables =images[test_image_num:test_image_num+training_image_num,:],label[test_image_num:test_image_num+training_image_num,:]\n",
        "\n",
        "# 1. Declare Weights\n",
        "w1 = np.random.randn(784,256) * 0.2\n",
        "w2 =np.random.randn(256,128) * 0.2\n",
        "w3 =np.random.randn(128,1) * 0.2\n",
        "\n",
        "w1_sgd,w2_sgd ,w3_sgd = w1,w2,w3\n",
        "w1_m,w2_m ,w3_m = w1,w2,w3\n",
        "w1_ng,w2_ng,w3_ng =  w1,w2,w3\n",
        "w1_adagrad,w2_adagrad,w3_adagrad =  w1,w2,w3\n",
        "w1_adadelta,w2_adadelta,w3_adadelta =  w1,w2,w3\n",
        "w1_RSMprop,w2_RSMprop,w3_RSMprop =  w1,w2,w3\n",
        "w1_adam,w2_adam,w3_adam =  w1,w2,w3\n",
        "w1_nadam,w2_nadam,w3_nadam =  w1,w2,w3\n",
        "\n",
        "w1_sgd_noise,w2_sgd_noise ,w3_sgd_noise = w1,w2,w3\n",
        "w1_noise,w2_noise,w3_noise  = w1,w2,w3\n",
        "w1_noise_noise,w2_noise_noise,w3_noise_noise  = w1,w2,w3\n",
        "w1_noise_adam,w2_noise_adam,w3_noise_adam  = w1,w2,w3\n",
        "\n",
        "\n",
        "\n",
        "# 2. SAME AMOUNT OF TRAINING\n",
        "num_epoch = 100\n",
        "total_cost = 0\n",
        "learn_rate = 0.0003\n",
        "cost_array =[]\n",
        "\n",
        "# # a. SGD\n",
        "cost_temp_array = []\n",
        "for iter in range(num_epoch):\n",
        "    for image_index in range(len(training_images)):\n",
        "        \n",
        "        current_image = np.expand_dims(training_images[image_index],axis=0)\n",
        "        current_image_label = np.expand_dims(training_lables[image_index],axis=1)\n",
        "\n",
        "        l1 = current_image.dot(w1_sgd)\n",
        "        l1A = elu(l1)\n",
        "\n",
        "        l2 = l1A.dot(w2_sgd)\n",
        "        l2A = tanh(l2)       \n",
        "\n",
        "        l3 = l2A.dot(w3_sgd)\n",
        "        l3A = log(l3)   \n",
        "\n",
        "        cost = np.square(l3A - current_image_label).sum() * 0.5\n",
        "        total_cost = total_cost + cost\n",
        "\n",
        "        grad_3_part_1 = l3A - current_image_label\n",
        "        grad_3_part_2 = d_log(l3)\n",
        "        grad_3_part_3 = l2A\n",
        "        grad_3 =     grad_3_part_3.T.dot(grad_3_part_1 * grad_3_part_2)    \n",
        "\n",
        "        grad_2_part_1 = (grad_3_part_1 * grad_3_part_2).dot(w3_sgd.T)\n",
        "        grad_2_part_2 = d_tanh(l2)\n",
        "        grad_2_part_3 = l1A\n",
        "        grad_2 =    grad_2_part_3.T.dot(grad_2_part_1 * grad_2_part_2)\n",
        "\n",
        "        grad_1_part_1 = (grad_2_part_1 * grad_2_part_2).dot(w2_sgd.T)\n",
        "        grad_1_part_2 = d_elu(l1)\n",
        "        grad_1_part_3 = current_image\n",
        "        grad_1 =   grad_1_part_3.T.dot(grad_1_part_1 *grad_1_part_2)\n",
        "\n",
        "        w3_sgd = w3_sgd - learn_rate * grad_3\n",
        "        w2_sgd = w2_sgd - learn_rate * grad_2\n",
        "        w1_sgd = w1_sgd - learn_rate * grad_1\n",
        "    if iter %10 == 0 :\n",
        "        print(\"a. SGD current Iter: \", iter, \" Total Cost: \", total_cost)\n",
        "    cost_temp_array.append(total_cost)\n",
        "    total_cost = 0\n",
        "cost_array.append(cost_temp_array)\n",
        "# # ----------------------\n",
        "\n",
        "# # b. Momentum\n",
        "v1,v2,v3 = 0,0,0\n",
        "alpha = 0.001\n",
        "total_cost = 0\n",
        "cost_temp_array = []\n",
        "print('-------------------------')\n",
        "for iter in range(num_epoch):\n",
        "    for image_index in range(len(training_images)):\n",
        "        \n",
        "        current_image = np.expand_dims(training_images[image_index],axis=0)\n",
        "        current_image_label = np.expand_dims(training_lables[image_index],axis=1)\n",
        "\n",
        "        l1 = current_image.dot(w1_m)\n",
        "        l1A = elu(l1)\n",
        "\n",
        "        l2 = l1A.dot(w2_m)\n",
        "        l2A = tanh(l2)       \n",
        "\n",
        "        l3 = l2A.dot(w3_m)\n",
        "        l3A = log(l3)   \n",
        "\n",
        "        cost = np.square(l3A - current_image_label).sum() * 0.5\n",
        "        total_cost = total_cost + cost\n",
        "\n",
        "        grad_3_part_1 = l3A - current_image_label\n",
        "        grad_3_part_2 = d_log(l3)\n",
        "        grad_3_part_3 = l2A\n",
        "        grad_3 =     grad_3_part_3.T.dot(grad_3_part_1 * grad_3_part_2)    \n",
        "\n",
        "        grad_2_part_1 = (grad_3_part_1 * grad_3_part_2).dot(w3_m.T)\n",
        "        grad_2_part_2 = d_tanh(l2)\n",
        "        grad_2_part_3 = l1A\n",
        "        grad_2 =    grad_2_part_3.T.dot(grad_2_part_1 * grad_2_part_2)\n",
        "\n",
        "        grad_1_part_1 = (grad_2_part_1 * grad_2_part_2).dot(w2_m.T)\n",
        "        grad_1_part_2 = d_elu(l1)\n",
        "        grad_1_part_3 = current_image\n",
        "        grad_1 =   grad_1_part_3.T.dot(grad_1_part_1 *grad_1_part_2)\n",
        "\n",
        "        v3 = v3 * alpha + learn_rate * grad_3\n",
        "        v2 = v2 * alpha + learn_rate * grad_2\n",
        "        v1 = v1 * alpha + learn_rate * grad_1\n",
        "\n",
        "        w3_m = w3_m - v3\n",
        "        w2_m = w2_m - v2\n",
        "        w1_m = w1_m - v1\n",
        "    if iter %10 == 0 :\n",
        "        print(\"b. Momentum current Iter: \", iter, \" Total Cost: \", total_cost)\n",
        "    cost_temp_array.append(total_cost)\n",
        "    total_cost = 0\n",
        "cost_array.append(cost_temp_array)\n",
        "# # ----------------------\n",
        "\n",
        "\n",
        "# # c. Nesterov accelerated gradient\n",
        "v1,v2,v3 = 0,0,0\n",
        "alpha = 0.001\n",
        "total_cost = 0\n",
        "cost_temp_array = []\n",
        "print('-------------------------')\n",
        "for iter in range(num_epoch):\n",
        "    for image_index in range(len(training_images)):\n",
        "        \n",
        "        current_image = np.expand_dims(training_images[image_index],axis=0)\n",
        "        current_image_label = np.expand_dims(training_lables[image_index],axis=1)\n",
        "\n",
        "        l1 = current_image.dot(w1_ng)\n",
        "        l1A = elu(l1)\n",
        "\n",
        "        l2 = l1A.dot(w2_ng)\n",
        "        l2A = tanh(l2)       \n",
        "\n",
        "        l3 = l2A.dot(w3_ng)\n",
        "        l3A = log(l3)   \n",
        "\n",
        "        cost = np.square(l3A - current_image_label).sum() * 0.5\n",
        "        total_cost = total_cost + cost\n",
        "\n",
        "        grad_3_part_1 = l3A - current_image_label\n",
        "        grad_3_part_2 = d_log(l3)\n",
        "        grad_3_part_3 = l2A\n",
        "        grad_3 =     grad_3_part_3.T.dot(grad_3_part_1 * grad_3_part_2)    \n",
        "\n",
        "        grad_2_part_1 = (grad_3_part_1 * grad_3_part_2).dot(w3_ng.T)\n",
        "        grad_2_part_2 = d_tanh(l2)\n",
        "        grad_2_part_3 = l1A\n",
        "        grad_2 =    grad_2_part_3.T.dot(grad_2_part_1 * grad_2_part_2)\n",
        "\n",
        "        grad_1_part_1 = (grad_2_part_1 * grad_2_part_2).dot(w2_ng.T)\n",
        "        grad_1_part_2 = d_elu(l1)\n",
        "        grad_1_part_3 = current_image\n",
        "        grad_1 =   grad_1_part_3.T.dot(grad_1_part_1 *grad_1_part_2)\n",
        "\n",
        "        # ------- FAKE GRADIENT --------\n",
        "        fake_w3_ng = w3_ng - alpha * v3\n",
        "        fake_w2_ng = w2_ng - alpha * v2\n",
        "        fake_w1_ng = w1_ng - alpha * v1\n",
        "        \n",
        "        l1 = current_image.dot(fake_w1_ng)\n",
        "        l1A = elu(l1)\n",
        "\n",
        "        l2 = l1A.dot(fake_w2_ng)\n",
        "        l2A = tanh(l2)       \n",
        "\n",
        "        l3 = l2A.dot(fake_w3_ng)\n",
        "        l3A = log(l3)   \n",
        "\n",
        "        grad_3_part_1 = l3A - current_image_label\n",
        "        grad_3_part_2 = d_log(l3)\n",
        "        grad_3_part_3 = l2A\n",
        "        grad_3_fake =     grad_3_part_3.T.dot(grad_3_part_1 * grad_3_part_2)    \n",
        "\n",
        "        grad_2_part_1 = (grad_3_part_1 * grad_3_part_2).dot(fake_w3_ng.T)\n",
        "        grad_2_part_2 = d_tanh(l2)\n",
        "        grad_2_part_3 = l1A\n",
        "        grad_2_fake =    grad_2_part_3.T.dot(grad_2_part_1 * grad_2_part_2)\n",
        "\n",
        "        grad_1_part_1 = (grad_2_part_1 * grad_2_part_2).dot(fake_w2_ng.T)\n",
        "        grad_1_part_2 = d_elu(l1)\n",
        "        grad_1_part_3 = current_image\n",
        "        grad_1_fake =   grad_1_part_3.T.dot(grad_1_part_1 *grad_1_part_2)\n",
        "        # ------- FAKE GRADIENT --------\n",
        "\n",
        "        v3 = v3 * alpha + learn_rate * grad_3_fake\n",
        "        v2 = v2 * alpha + learn_rate * grad_2_fake\n",
        "        v1 = v1 * alpha + learn_rate * grad_1_fake\n",
        "\n",
        "        w3_ng = w3_ng - v3\n",
        "        w2_ng = w2_ng - v2\n",
        "        w1_ng = w1_ng - v1\n",
        "    if iter %10 == 0 :\n",
        "        print(\"c. Nesterov accelerated gradient current Iter: \", iter, \" Total Cost: \", total_cost)\n",
        "    cost_temp_array.append(total_cost)\n",
        "    total_cost = 0\n",
        "cost_array.append(cost_temp_array)\n",
        "# # ----------------------\n",
        "\n",
        "\n",
        "# # d. Adagrad\n",
        "Adagrad_lr_1,Adagrad_lr_2,Adagrad_lr_3 = 0,0,0\n",
        "Adagrad_e = 0.00000001\n",
        "total_cost = 0\n",
        "cost_temp_array = []\n",
        "print('-------------------------')\n",
        "for iter in range(num_epoch):\n",
        "    for image_index in range(len(training_images)):\n",
        "        \n",
        "        current_image = np.expand_dims(training_images[image_index],axis=0)\n",
        "        current_image_label = np.expand_dims(training_lables[image_index],axis=1)\n",
        "\n",
        "        l1 = current_image.dot(w1_adagrad)\n",
        "        l1A = elu(l1)\n",
        "\n",
        "        l2 = l1A.dot(w2_adagrad)\n",
        "        l2A = tanh(l2)       \n",
        "\n",
        "        l3 = l2A.dot(w3_adagrad)\n",
        "        l3A = log(l3)   \n",
        "\n",
        "        cost = np.square(l3A - current_image_label).sum() * 0.5\n",
        "        total_cost = total_cost + cost\n",
        "\n",
        "        grad_3_part_1 = l3A - current_image_label\n",
        "        grad_3_part_2 = d_log(l3)\n",
        "        grad_3_part_3 = l2A\n",
        "        grad_3 =     grad_3_part_3.T.dot(grad_3_part_1 * grad_3_part_2)    \n",
        "\n",
        "        grad_2_part_1 = (grad_3_part_1 * grad_3_part_2).dot(w3_adagrad.T)\n",
        "        grad_2_part_2 = d_tanh(l2)\n",
        "        grad_2_part_3 = l1A\n",
        "        grad_2 =    grad_2_part_3.T.dot(grad_2_part_1 * grad_2_part_2)\n",
        "\n",
        "        grad_1_part_1 = (grad_2_part_1 * grad_2_part_2).dot(w2_adagrad.T)\n",
        "        grad_1_part_2 = d_elu(l1)\n",
        "        grad_1_part_3 = current_image\n",
        "        grad_1 =   grad_1_part_3.T.dot(grad_1_part_1 *grad_1_part_2)\n",
        "\n",
        "        Adagrad_lr_3 = Adagrad_lr_3 + grad_3 ** 2\n",
        "        Adagrad_lr_2 = Adagrad_lr_2 + grad_2 ** 2\n",
        "        Adagrad_lr_1 = Adagrad_lr_1 + grad_1 ** 2\n",
        "\n",
        "        w3_adagrad = w3_adagrad - (learn_rate/np.sqrt(Adagrad_lr_3 + Adagrad_e)) *grad_3\n",
        "        w2_adagrad = w2_adagrad - (learn_rate/np.sqrt(Adagrad_lr_2 + Adagrad_e)) *grad_2\n",
        "        w1_adagrad = w1_adagrad - (learn_rate/np.sqrt(Adagrad_lr_1 + Adagrad_e)) *grad_1\n",
        "    if iter %10 == 0 :\n",
        "        print(\"d. Adagrad current Iter: \", iter, \" Total Cost: \", total_cost)\n",
        "    cost_temp_array.append(total_cost)\n",
        "    total_cost = 0\n",
        "cost_array.append(cost_temp_array)\n",
        "# ----------------------\n",
        "\n",
        "\n",
        "# e. Adadelta\n",
        "AdaDelta_e,AdaDelta_v = 0.000001,0.001\n",
        "AdaDelta_1,AdaDelta_2,AdaDelta_3 = 0,0,0\n",
        "AdaDelta_1_v,AdaDelta_2_v,AdaDelta_3_v = 0,0,0\n",
        "total_cost = 0\n",
        "cost_temp_array = []\n",
        "print('-------------------------')\n",
        "for iter in range(num_epoch):\n",
        "    for image_index in range(len(training_images)):\n",
        "        \n",
        "        current_image = np.expand_dims(training_images[image_index],axis=0)\n",
        "        current_image_label = np.expand_dims(training_lables[image_index],axis=1)\n",
        "\n",
        "        l1 = current_image.dot(w1_adadelta)\n",
        "        l1A = elu(l1)\n",
        "\n",
        "        l2 = l1A.dot(w2_adadelta)\n",
        "        l2A = tanh(l2)       \n",
        "\n",
        "        l3 = l2A.dot(w3_adadelta)\n",
        "        l3A = log(l3)   \n",
        "\n",
        "        cost = np.square(l3A - current_image_label).sum() * 0.5\n",
        "        total_cost = total_cost + cost\n",
        "\n",
        "        grad_3_part_1 = l3A - current_image_label\n",
        "        grad_3_part_2 = d_log(l3)\n",
        "        grad_3_part_3 = l2A\n",
        "        grad_3 =     grad_3_part_3.T.dot(grad_3_part_1 * grad_3_part_2)    \n",
        "\n",
        "        grad_2_part_1 = (grad_3_part_1 * grad_3_part_2).dot(w3_adadelta.T)\n",
        "        grad_2_part_2 = d_tanh(l2)\n",
        "        grad_2_part_3 = l1A\n",
        "        grad_2 =    grad_2_part_3.T.dot(grad_2_part_1 * grad_2_part_2)\n",
        "\n",
        "        grad_1_part_1 = (grad_2_part_1 * grad_2_part_2).dot(w2_adadelta.T)\n",
        "        grad_1_part_2 = d_elu(l1)\n",
        "        grad_1_part_3 = current_image\n",
        "        grad_1 =   grad_1_part_3.T.dot(grad_1_part_1 *grad_1_part_2)\n",
        "\n",
        "        AdaDelta_3 = AdaDelta_v * AdaDelta_3 + (1-AdaDelta_v) * grad_3 ** 2\n",
        "        AdaDelta_2 = AdaDelta_v * AdaDelta_2 + (1-AdaDelta_v) * grad_2 ** 2\n",
        "        AdaDelta_1 = AdaDelta_v * AdaDelta_1 + (1-AdaDelta_v) * grad_1 ** 2\n",
        "\n",
        "        mid_grad_3 = - ( np.sqrt(AdaDelta_3_v + AdaDelta_e) / np.sqrt(AdaDelta_3 + AdaDelta_e) ) * grad_3\n",
        "        mid_grad_2 = - ( np.sqrt(AdaDelta_2_v + AdaDelta_e) / np.sqrt(AdaDelta_2 + AdaDelta_e) ) * grad_2\n",
        "        mid_grad_1 = - ( np.sqrt(AdaDelta_1_v + AdaDelta_e) / np.sqrt(AdaDelta_1 + AdaDelta_e) ) * grad_1\n",
        "\n",
        "        AdaDelta_3_v = AdaDelta_v * AdaDelta_3_v + (1-AdaDelta_v) * mid_grad_3 ** 2\n",
        "        AdaDelta_2_v = AdaDelta_v * AdaDelta_2_v + (1-AdaDelta_v) * mid_grad_2 ** 2\n",
        "        AdaDelta_1_v = AdaDelta_v * AdaDelta_1_v + (1-AdaDelta_v) * mid_grad_1 ** 2\n",
        "\n",
        "        w3_adadelta = w3_adadelta - mid_grad_3\n",
        "        w2_adadelta = w2_adadelta - mid_grad_2\n",
        "        w1_adadelta = w1_adadelta - mid_grad_1\n",
        "    if iter %10 == 0 :\n",
        "        print(\"e. Adadelta current Iter: \", iter, \" Total Cost: \", total_cost)\n",
        "\n",
        "    cost_temp_array.append(total_cost)\n",
        "    total_cost = 0\n",
        "cost_array.append(cost_temp_array)\n",
        "# ----------------------\n",
        "\n",
        "\n",
        "# f. RMSprop\n",
        "RMSprop_1,RMSprop_2,RMSprop_3 = 0,0,0\n",
        "RMSprop_v,RMSprop_e= 0.9,0.00000001\n",
        "total_cost = 0\n",
        "cost_temp_array = []\n",
        "print('-------------------------')\n",
        "for iter in range(num_epoch):\n",
        "    for image_index in range(len(training_images)):\n",
        "        \n",
        "        current_image = np.expand_dims(training_images[image_index],axis=0)\n",
        "        current_image_label = np.expand_dims(training_lables[image_index],axis=1)\n",
        "\n",
        "        l1 = current_image.dot(w1_RSMprop)\n",
        "        l1A = elu(l1)\n",
        "\n",
        "        l2 = l1A.dot(w2_RSMprop)\n",
        "        l2A = tanh(l2)       \n",
        "\n",
        "        l3 = l2A.dot(w3_RSMprop)\n",
        "        l3A = log(l3)   \n",
        "\n",
        "        cost = np.square(l3A - current_image_label).sum() * 0.5\n",
        "        total_cost = total_cost + cost\n",
        "\n",
        "        grad_3_part_1 = l3A - current_image_label\n",
        "        grad_3_part_2 = d_log(l3)\n",
        "        grad_3_part_3 = l2A\n",
        "        grad_3 =     grad_3_part_3.T.dot(grad_3_part_1 * grad_3_part_2)    \n",
        "\n",
        "        grad_2_part_1 = (grad_3_part_1 * grad_3_part_2).dot(w3_RSMprop.T)\n",
        "        grad_2_part_2 = d_tanh(l2)\n",
        "        grad_2_part_3 = l1A\n",
        "        grad_2 =    grad_2_part_3.T.dot(grad_2_part_1 * grad_2_part_2)\n",
        "\n",
        "        grad_1_part_1 = (grad_2_part_1 * grad_2_part_2).dot(w2_RSMprop.T)\n",
        "        grad_1_part_2 = d_elu(l1)\n",
        "        grad_1_part_3 = current_image\n",
        "        grad_1 =   grad_1_part_3.T.dot(grad_1_part_1 *grad_1_part_2)\n",
        "\n",
        "        RMSprop_3 = RMSprop_v*RMSprop_3 + (1- RMSprop_v)*grad_3**2\n",
        "        RMSprop_2 = RMSprop_v*RMSprop_2 + (1- RMSprop_v)*grad_2**2\n",
        "        RMSprop_1 = RMSprop_v*RMSprop_1 + (1- RMSprop_v)*grad_1**2\n",
        "\n",
        "        w3_RSMprop = w3_RSMprop - (learn_rate/np.sqrt(RMSprop_3 + RMSprop_e)) * grad_3\n",
        "        w2_RSMprop = w2_RSMprop - (learn_rate/np.sqrt(RMSprop_2 + RMSprop_e)) * grad_2\n",
        "        w1_RSMprop = w1_RSMprop - (learn_rate/np.sqrt(RMSprop_1 + RMSprop_e)) * grad_1\n",
        "    if iter %10 == 0 :\n",
        "        print(\"f. RMSprop current Iter: \", iter, \" Total Cost: \", total_cost)\n",
        "    cost_temp_array.append(total_cost)\n",
        "    total_cost = 0\n",
        "cost_array.append(cost_temp_array)\n",
        "# ----------------------\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# g. Adam\n",
        "Adam_m_1,Adam_m_2,Adam_m_3 = 0,0,0\n",
        "Adam_v_1,Adam_v_2,Adam_v_3 = 0,0,0\n",
        "Adam_Beta_1,Adam_Beta_2 = 0.9,0.999\n",
        "Adam_e = 0.00000001\n",
        "total_cost = 0\n",
        "cost_temp_array = []\n",
        "print('-------------------------')\n",
        "for iter in range(num_epoch):\n",
        "    for image_index in range(len(training_images)):\n",
        "        \n",
        "        current_image = np.expand_dims(training_images[image_index],axis=0)\n",
        "        current_image_label = np.expand_dims(training_lables[image_index],axis=1)\n",
        "\n",
        "        l1 = current_image.dot(w1_adam)\n",
        "        l1A = elu(l1)\n",
        "\n",
        "        l2 = l1A.dot(w2_adam)\n",
        "        l2A = tanh(l2)       \n",
        "\n",
        "        l3 = l2A.dot(w3_adam)\n",
        "        l3A = log(l3)   \n",
        "\n",
        "        cost = np.square(l3A - current_image_label).sum() * 0.5\n",
        "        total_cost = total_cost + cost\n",
        "\n",
        "        grad_3_part_1 = l3A - current_image_label\n",
        "        grad_3_part_2 = d_log(l3)\n",
        "        grad_3_part_3 = l2A\n",
        "        grad_3 =     grad_3_part_3.T.dot(grad_3_part_1 * grad_3_part_2)    \n",
        "\n",
        "        grad_2_part_1 = (grad_3_part_1 * grad_3_part_2).dot(w3_adam.T)\n",
        "        grad_2_part_2 = d_tanh(l2)\n",
        "        grad_2_part_3 = l1A\n",
        "        grad_2 =    grad_2_part_3.T.dot(grad_2_part_1 * grad_2_part_2)\n",
        "\n",
        "        grad_1_part_1 = (grad_2_part_1 * grad_2_part_2).dot(w2_adam.T)\n",
        "        grad_1_part_2 = d_elu(l1)\n",
        "        grad_1_part_3 = current_image\n",
        "        grad_1 =   grad_1_part_3.T.dot(grad_1_part_1 *grad_1_part_2)\n",
        "\n",
        "        Adam_m_3 = Adam_Beta_1 * Adam_m_3 + ( 1-Adam_Beta_1 ) *grad_3\n",
        "        Adam_m_2 = Adam_Beta_1 * Adam_m_2 + ( 1-Adam_Beta_1 ) *grad_2\n",
        "        Adam_m_1 = Adam_Beta_1 * Adam_m_1 + ( 1-Adam_Beta_1 ) *grad_1\n",
        "\n",
        "        Adam_v_3 = Adam_Beta_2 * Adam_v_3 + ( 1-Adam_Beta_2 ) *grad_3 **2 \n",
        "        Adam_v_2 = Adam_Beta_2 * Adam_v_2 + ( 1-Adam_Beta_2 ) *grad_2 **2 \n",
        "        Adam_v_1 = Adam_Beta_2 * Adam_v_1 + ( 1-Adam_Beta_2 ) *grad_1 **2 \n",
        "        \n",
        "        Adam_m_3_hat = Adam_m_3/(1-Adam_Beta_1)\n",
        "        Adam_m_2_hat = Adam_m_2/(1-Adam_Beta_1)\n",
        "        Adam_m_1_hat = Adam_m_1/(1-Adam_Beta_1)\n",
        "        \n",
        "        Adam_v_3_hat = Adam_v_3/(1-Adam_Beta_2)\n",
        "        Adam_v_2_hat = Adam_v_2/(1-Adam_Beta_2)\n",
        "        Adam_v_1_hat = Adam_v_1/(1-Adam_Beta_2)\n",
        "        \n",
        "        w3_adam = w3_adam - (learn_rate/(np.sqrt(Adam_v_3_hat) + Adam_e)) * Adam_m_3_hat\n",
        "        w2_adam = w2_adam - (learn_rate/(np.sqrt(Adam_v_2_hat) + Adam_e)) * Adam_m_2_hat\n",
        "        w1_adam = w1_adam - (learn_rate/(np.sqrt(Adam_v_1_hat) + Adam_e)) * Adam_m_1_hat\n",
        "        \n",
        "    if iter %10 == 0 :\n",
        "        print(\"g. Adam current Iter: \", iter, \" Total Cost: \", total_cost)\n",
        "    cost_temp_array.append(total_cost)\n",
        "    total_cost = 0\n",
        "cost_array.append(cost_temp_array)\n",
        "# ----------------------\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# h. Nadam\n",
        "Nadam_m_1,Nadam_m_2,Nadam_m_3 = 0,0,0\n",
        "Nadam_v_1,Nadam_v_2,Nadam_v_3 = 0,0,0\n",
        "Nadam_Beta_1,Nadam_Beta_2 = 0.9,0.999\n",
        "Nadam_e = 0.00000001\n",
        "total_cost = 0\n",
        "cost_temp_array = []\n",
        "print('-------------------------')\n",
        "for iter in range(num_epoch):\n",
        "    for image_index in range(len(training_images)):\n",
        "        \n",
        "        current_image = np.expand_dims(training_images[image_index],axis=0)\n",
        "        current_image_label = np.expand_dims(training_lables[image_index],axis=1)\n",
        "\n",
        "        l1 = current_image.dot(w1_nadam)\n",
        "        l1A = elu(l1)\n",
        "\n",
        "        l2 = l1A.dot(w2_nadam)\n",
        "        l2A = tanh(l2)       \n",
        "\n",
        "        l3 = l2A.dot(w3_nadam)\n",
        "        l3A = log(l3)   \n",
        "\n",
        "        cost = np.square(l3A - current_image_label).sum() * 0.5\n",
        "        total_cost = total_cost + cost\n",
        "\n",
        "        grad_3_part_1 = l3A - current_image_label\n",
        "        grad_3_part_2 = d_log(l3)\n",
        "        grad_3_part_3 = l2A\n",
        "        grad_3 =     grad_3_part_3.T.dot(grad_3_part_1 * grad_3_part_2)    \n",
        "\n",
        "        grad_2_part_1 = (grad_3_part_1 * grad_3_part_2).dot(w3_nadam.T)\n",
        "        grad_2_part_2 = d_tanh(l2)\n",
        "        grad_2_part_3 = l1A\n",
        "        grad_2 =    grad_2_part_3.T.dot(grad_2_part_1 * grad_2_part_2)\n",
        "\n",
        "        grad_1_part_1 = (grad_2_part_1 * grad_2_part_2).dot(w2_nadam.T)\n",
        "        grad_1_part_2 = d_elu(l1)\n",
        "        grad_1_part_3 = current_image\n",
        "        grad_1 =   grad_1_part_3.T.dot(grad_1_part_1 *grad_1_part_2)\n",
        "\n",
        "        Nadam_m_3 = Nadam_Beta_1 * Nadam_m_3 + (1 - Nadam_Beta_1) * grad_3\n",
        "        Nadam_m_2 = Nadam_Beta_1 * Nadam_m_2 + (1 - Nadam_Beta_1) * grad_2\n",
        "        Nadam_m_1 = Nadam_Beta_1 * Nadam_m_1 + (1 - Nadam_Beta_1) * grad_1\n",
        "        \n",
        "        Nadam_v_3 = Nadam_Beta_2 * Nadam_v_3 + (1- Nadam_Beta_2) * grad_3 ** 2\n",
        "        Nadam_v_2 = Nadam_Beta_2 * Nadam_v_2 + (1- Nadam_Beta_2) * grad_2 ** 2\n",
        "        Nadam_v_1 = Nadam_Beta_2 * Nadam_v_1 + (1- Nadam_Beta_2) * grad_1 ** 2\n",
        "\n",
        "        Nadam_m_3_hat = Nadam_m_3/ (1 - Nadam_Beta_1)\n",
        "        Nadam_m_2_hat = Nadam_m_2/ (1 - Nadam_Beta_1)\n",
        "        Nadam_m_1_hat = Nadam_m_1/ (1 - Nadam_Beta_1)\n",
        "\n",
        "        Nadam_v_3_hat = Nadam_v_3/ (1 - Nadam_Beta_2)\n",
        "        Nadam_v_2_hat = Nadam_v_2/ (1 - Nadam_Beta_2)\n",
        "        Nadam_v_1_hat = Nadam_v_1/ (1 - Nadam_Beta_2)\n",
        "         \n",
        "        w3_nadam = w3_nadam - (learn_rate/( np.sqrt(Nadam_v_3_hat) + Nadam_e )) * ( Nadam_Beta_1  * Nadam_m_3_hat + ( ( (1-Nadam_Beta_1) * grad_3 ) / (1 - Nadam_Beta_1)  ) )\n",
        "        w2_nadam = w2_nadam - (learn_rate/( np.sqrt(Nadam_v_2_hat) + Nadam_e )) * ( Nadam_Beta_1  * Nadam_m_2_hat + ( ( (1-Nadam_Beta_1) * grad_2 ) / (1 - Nadam_Beta_1)  ) )\n",
        "        w1_nadam = w1_nadam - (learn_rate/( np.sqrt(Nadam_v_1_hat) + Nadam_e )) * ( Nadam_Beta_1  * Nadam_m_1_hat + ( ( (1-Nadam_Beta_1) * grad_1 ) / (1 - Nadam_Beta_1)  ) )\n",
        "    if iter %10 == 0 :\n",
        "        print(\"h. Nadam current Iter: \", iter, \" Total Cost: \", total_cost)\n",
        "    cost_temp_array.append(total_cost)\n",
        "    total_cost = 0\n",
        "cost_array.append(cost_temp_array)\n",
        "# ----------------------\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# i. SGD with Gaussian Noise\n",
        "print('-------------------------')\n",
        "total_cost = 0\n",
        "n_value = 0.001\n",
        "cost_temp_array = []\n",
        "for iter in range(num_epoch):\n",
        "    for image_index in range(len(training_images)):\n",
        "        \n",
        "        current_image = np.expand_dims(training_images[image_index],axis=0)\n",
        "        current_image_label = np.expand_dims(training_lables[image_index],axis=1)\n",
        "\n",
        "        l1 = current_image.dot(w1_sgd_noise)\n",
        "        l1A = elu(l1)\n",
        "\n",
        "        l2 = l1A.dot(w2_sgd_noise)\n",
        "        l2A = tanh(l2)       \n",
        "\n",
        "        l3 = l2A.dot(w3_sgd_noise)\n",
        "        l3A = log(l3)   \n",
        "\n",
        "        cost = np.square(l3A - current_image_label).sum() * 0.5\n",
        "        total_cost = total_cost + cost\n",
        "\n",
        "        grad_3_part_1 = l3A - current_image_label\n",
        "        grad_3_part_2 = d_log(l3)\n",
        "        grad_3_part_3 = l2A\n",
        "        grad_3 =     grad_3_part_3.T.dot(grad_3_part_1 * grad_3_part_2)    \n",
        "\n",
        "        grad_2_part_1 = (grad_3_part_1 * grad_3_part_2).dot(w3_sgd_noise.T)\n",
        "        grad_2_part_2 = d_tanh(l2)\n",
        "        grad_2_part_3 = l1A\n",
        "        grad_2 =    grad_2_part_3.T.dot(grad_2_part_1 * grad_2_part_2)\n",
        "\n",
        "        grad_1_part_1 = (grad_2_part_1 * grad_2_part_2).dot(w2_sgd_noise.T)\n",
        "        grad_1_part_2 = d_elu(l1)\n",
        "        grad_1_part_3 = current_image\n",
        "        grad_1 =   grad_1_part_3.T.dot(grad_1_part_1 *grad_1_part_2)\n",
        "\n",
        "        # ------ Calculate The Additive Noise -------\n",
        "        ADDITIVE_NOISE_STD = n_value / (np.power((1 + iter), 0.55))\n",
        "        ADDITIVE_GAUSSIAN_NOISE = np.random.normal(loc=0,scale=ADDITIVE_NOISE_STD)\n",
        "        # ------ Calculate The Additive Noise -------\n",
        "\n",
        "        w3_sgd_noise = w3_sgd_noise - learn_rate* (grad_3 + ADDITIVE_GAUSSIAN_NOISE)\n",
        "        w2_sgd_noise = w2_sgd_noise - learn_rate* (grad_2 + ADDITIVE_GAUSSIAN_NOISE)\n",
        "        w1_sgd_noise = w1_sgd_noise - learn_rate* (grad_1 + ADDITIVE_GAUSSIAN_NOISE)\n",
        "    if iter %10 == 0 :\n",
        "        print(\"i. SGD with Gaussian Noise current Iter: \", iter, \" Total Cost: \", total_cost)\n",
        "    cost_temp_array.append(total_cost)\n",
        "    total_cost = 0\n",
        "cost_array.append(cost_temp_array)\n",
        "# ----------------------\n",
        "\n",
        "# --- Adjust Learning Rate for Noises -----------\n",
        "learn_rate = 0.00001\n",
        "# --- Adjust Learning Rate for Noises -----------\n",
        "\n",
        "# j. noise training\n",
        "print('-------------------------')\n",
        "total_cost = 0\n",
        "n, p = 1, .5 \n",
        "cost_temp_array = []\n",
        "for iter in range(num_epoch):\n",
        "    for image_index in range(len(training_images)):\n",
        "        \n",
        "        current_image = np.expand_dims(training_images[image_index],axis=0)\n",
        "        current_image_label = np.expand_dims(training_lables[image_index],axis=1)\n",
        "\n",
        "        l1 = current_image.dot(w1_noise)\n",
        "        l1A = elu(l1)\n",
        "\n",
        "        l2 = l1A.dot(w2_noise)\n",
        "        l2A = tanh(l2)       \n",
        "\n",
        "        l3 = l2A.dot(w3_noise)\n",
        "        l3A = log(l3)   \n",
        "\n",
        "        cost = np.square(l3A - current_image_label).sum() * 0.5\n",
        "        total_cost = total_cost + cost\n",
        "\n",
        "        gradient_weight_3 = np.random.gumbel(size=w3.shape)\n",
        "        gradient_weight_2 = np.random.gumbel(size=w2.shape)\n",
        "        gradient_weight_1 = np.random.gumbel(size=w1.shape)\n",
        "\n",
        "        w3_noise = w3_noise - learn_rate* gradient_weight_3\n",
        "        w2_noise = w2_noise - learn_rate* gradient_weight_2\n",
        "        w1_noise = w1_noise - learn_rate* gradient_weight_1\n",
        "    if iter %10 == 0 :\n",
        "        print(\"j. noise current Iter: \", iter, \" Total Cost: \", total_cost)\n",
        "    cost_temp_array.append(total_cost)\n",
        "    total_cost = 0\n",
        "        \n",
        "cost_array.append(cost_temp_array)\n",
        "# ----------------------\n",
        "\n",
        "\n",
        "# k. noise noise training\n",
        "print('-------------------------')\n",
        "total_cost = 0\n",
        "cost_temp_array = []\n",
        "for iter in range(num_epoch):\n",
        "    for image_index in range(len(training_images)):\n",
        "        \n",
        "        current_image = np.expand_dims(training_images[image_index],axis=0)\n",
        "        current_image_label = np.expand_dims(training_lables[image_index],axis=1)\n",
        "\n",
        "        l1 = current_image.dot(w1_noise_noise)\n",
        "        l1A = elu(l1)\n",
        "\n",
        "        l2 = l1A.dot(w2_noise_noise)\n",
        "        l2A = tanh(l2)       \n",
        "\n",
        "        l3 = l2A.dot(w3_noise_noise)\n",
        "        l3A = log(l3)   \n",
        "\n",
        "        cost = np.square(l3A - current_image_label).sum() * 0.5\n",
        "        total_cost = total_cost + cost\n",
        "\n",
        "        gradient_weight_3 = np.random.gumbel(size=w3.shape)\n",
        "        gradient_weight_2 = np.random.gumbel(size=w2.shape)\n",
        "        gradient_weight_1 = np.random.gumbel(size=w1.shape)\n",
        "\n",
        "        # ------ Calculate The Additive Noise -------\n",
        "        ADDITIVE_NOISE_STD = n_value / (np.power((1 + iter), 0.55))\n",
        "        ADDITIVE_GAUSSIAN_NOISE = np.random.normal(loc=0,scale=ADDITIVE_NOISE_STD)\n",
        "        # ------ Calculate The Additive Noise -------\n",
        "\n",
        "        w3_noise_noise = w3_noise_noise - learn_rate* (gradient_weight_3 + ADDITIVE_GAUSSIAN_NOISE)\n",
        "        w2_noise_noise = w2_noise_noise - learn_rate* (gradient_weight_2 + ADDITIVE_GAUSSIAN_NOISE)\n",
        "        w1_noise_noise = w1_noise_noise - learn_rate* (gradient_weight_1 + ADDITIVE_GAUSSIAN_NOISE)\n",
        "    if iter %10 == 0 :\n",
        "        print(\"k. noise Noise current Iter: \", iter, \" Total Cost: \", total_cost)\n",
        "    cost_temp_array.append(total_cost)\n",
        "    total_cost = 0\n",
        "\n",
        "cost_array.append(cost_temp_array)\n",
        "# ----------------------\n",
        "\n",
        "\n",
        "# l. noise adam training\n",
        "print('-------------------------')\n",
        "total_cost = 0\n",
        "cost_temp_array = []\n",
        "noise_adam_m1,noise_adam_m2,noise_adam_m3 = 0,0,0\n",
        "noise_adam_v1,noise_adam_v2,noise_adam_v3 = 0,0,0\n",
        "noise_Adam_Beta_1,noise_Adam_Beta_2 = 0.9,0.999\n",
        "noise_Adam_e = 0.00000001\n",
        "for iter in range(num_epoch):\n",
        "    for image_index in range(len(training_images)):\n",
        "        \n",
        "        current_image = np.expand_dims(training_images[image_index],axis=0)\n",
        "        current_image_label = np.expand_dims(training_lables[image_index],axis=1)\n",
        "\n",
        "        l1 = current_image.dot(w1_noise_adam)\n",
        "        l1A = elu(l1)\n",
        "\n",
        "        l2 = l1A.dot(w2_noise_adam)\n",
        "        l2A = tanh(l2)       \n",
        "\n",
        "        l3 = l2A.dot(w3_noise_adam)\n",
        "        l3A = log(l3)   \n",
        "\n",
        "        cost = np.square(l3A - current_image_label).sum() * 0.5\n",
        "        total_cost = total_cost + cost\n",
        "\n",
        "        gradient_weight_3 = np.random.gumbel(size=w3.shape)\n",
        "        gradient_weight_2 = np.random.gumbel(size=w2.shape)\n",
        "        gradient_weight_1 = np.random.gumbel(size=w1.shape)\n",
        "\n",
        "        noise_adam_m3 = noise_Adam_Beta_1 * noise_adam_m3 + (1 - noise_Adam_Beta_1) * gradient_weight_3\n",
        "        noise_adam_m2 = noise_Adam_Beta_1 * noise_adam_m2 + (1 - noise_Adam_Beta_1) * gradient_weight_2\n",
        "        noise_adam_m1 = noise_Adam_Beta_1 * noise_adam_m1 + (1 - noise_Adam_Beta_1) * gradient_weight_1\n",
        "        \n",
        "        noise_adam_v3 = noise_Adam_Beta_2 * noise_adam_v3 + (1 - noise_Adam_Beta_2) * gradient_weight_3 ** 2\n",
        "        noise_adam_v2 = noise_Adam_Beta_2 * noise_adam_v2 + (1 - noise_Adam_Beta_2) * gradient_weight_2 ** 2\n",
        "        noise_adam_v1 = noise_Adam_Beta_2 * noise_adam_v1 + (1 - noise_Adam_Beta_2) * gradient_weight_1 ** 2\n",
        "\n",
        "        noise_adam_m3_hat = noise_adam_m3/(1 -noise_Adam_Beta_1 )\n",
        "        noise_adam_m2_hat = noise_adam_m2/(1 -noise_Adam_Beta_1 )\n",
        "        noise_adam_m1_hat = noise_adam_m1/(1 -noise_Adam_Beta_1 )\n",
        "\n",
        "        noise_adam_v3_hat = noise_adam_v3/(1 -noise_Adam_Beta_2 )\n",
        "        noise_adam_v2_hat = noise_adam_v2/(1 -noise_Adam_Beta_2 )\n",
        "        noise_adam_v1_hat = noise_adam_v1/(1 -noise_Adam_Beta_2 )\n",
        "\n",
        "        w3_noise_adam = w3_noise_adam - (learn_rate / ( np.sqrt(noise_adam_v3_hat)  +noise_Adam_e )) * noise_adam_m3_hat\n",
        "        w2_noise_adam = w2_noise_adam - (learn_rate / ( np.sqrt(noise_adam_v2_hat)  +noise_Adam_e )) * noise_adam_m2_hat\n",
        "        w1_noise_adam = w1_noise_adam - (learn_rate / ( np.sqrt(noise_adam_v1_hat)  +noise_Adam_e )) * noise_adam_m1_hat\n",
        "\n",
        "    if iter %10 == 0 :\n",
        "        print(\"l. noise adam current Iter: \", iter, \" Total Cost: \", total_cost)\n",
        "    cost_temp_array.append(total_cost)\n",
        "    total_cost = 0\n",
        "    \n",
        "    \n",
        "cost_array.append(cost_temp_array)\n",
        "\n",
        "bar_color = ['b', 'g', 'saddlebrown', 'steelblue', \n",
        "            'orangered', 'y', 'paleturquoise', 'royalblue',\n",
        "            'salmon','silver','skyblue','slateblue','peru','plum']\n",
        "labels_z = ['a','b','c','d','e','f','g','h','i','j','k','l']\n",
        "\n",
        "\n",
        "for i in range(len(cost_array)):\n",
        "    plt.plot(np.arange(num_epoch), cost_array[i],color=bar_color[i],linewidth=3,label=str(labels_z[i]) )\n",
        "plt.title(\"Total Cost per Training\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# -- end code --"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting ../MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting ../MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting ../MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting ../MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "a. SGD current Iter:  0  Total Cost:  9.669238632637636\n",
            "a. SGD current Iter:  10  Total Cost:  6.658670209978986\n",
            "a. SGD current Iter:  20  Total Cost:  4.709372140341866\n",
            "a. SGD current Iter:  30  Total Cost:  3.382775481452276\n",
            "a. SGD current Iter:  40  Total Cost:  2.4765219370284033\n",
            "a. SGD current Iter:  50  Total Cost:  1.9191721039126357\n",
            "a. SGD current Iter:  60  Total Cost:  1.5635729834782437\n",
            "a. SGD current Iter:  70  Total Cost:  1.3037538769335792\n",
            "a. SGD current Iter:  80  Total Cost:  1.1275937789349346\n",
            "a. SGD current Iter:  90  Total Cost:  0.9886932895582129\n",
            "-------------------------\n",
            "b. Momentum current Iter:  0  Total Cost:  9.669098156622722\n",
            "b. Momentum current Iter:  10  Total Cost:  6.6561671653883865\n",
            "b. Momentum current Iter:  20  Total Cost:  4.706207552650885\n",
            "b. Momentum current Iter:  30  Total Cost:  3.3794330279861664\n",
            "b. Momentum current Iter:  40  Total Cost:  2.4737081693501533\n",
            "b. Momentum current Iter:  50  Total Cost:  1.9170100072123717\n",
            "b. Momentum current Iter:  60  Total Cost:  1.561814567006864\n",
            "b. Momentum current Iter:  70  Total Cost:  1.3022376188387585\n",
            "b. Momentum current Iter:  80  Total Cost:  1.1263842918423677\n",
            "b. Momentum current Iter:  90  Total Cost:  0.9875030167757408\n",
            "-------------------------\n",
            "c. Nesterov accelerated gradient current Iter:  0  Total Cost:  9.6690982587385\n",
            "c. Nesterov accelerated gradient current Iter:  10  Total Cost:  6.6561685290306745\n",
            "c. Nesterov accelerated gradient current Iter:  20  Total Cost:  4.706209498504621\n",
            "c. Nesterov accelerated gradient current Iter:  30  Total Cost:  3.3794347400059084\n",
            "c. Nesterov accelerated gradient current Iter:  40  Total Cost:  2.4737091572684347\n",
            "c. Nesterov accelerated gradient current Iter:  50  Total Cost:  1.9170104906121708\n",
            "c. Nesterov accelerated gradient current Iter:  60  Total Cost:  1.561814859863915\n",
            "c. Nesterov accelerated gradient current Iter:  70  Total Cost:  1.302237977369435\n",
            "c. Nesterov accelerated gradient current Iter:  80  Total Cost:  1.1263848362332571\n",
            "c. Nesterov accelerated gradient current Iter:  90  Total Cost:  0.9875038840999113\n",
            "-------------------------\n",
            "d. Adagrad current Iter:  0  Total Cost:  8.560107677088666\n",
            "d. Adagrad current Iter:  10  Total Cost:  4.889990183478938\n",
            "d. Adagrad current Iter:  20  Total Cost:  3.9044519189250586\n",
            "d. Adagrad current Iter:  30  Total Cost:  3.3779988587306353\n",
            "d. Adagrad current Iter:  40  Total Cost:  2.997309289232949\n",
            "d. Adagrad current Iter:  50  Total Cost:  2.6854141209821876\n",
            "d. Adagrad current Iter:  60  Total Cost:  2.4129916408864087\n",
            "d. Adagrad current Iter:  70  Total Cost:  2.171947874062912\n",
            "d. Adagrad current Iter:  80  Total Cost:  1.9788563464725306\n",
            "d. Adagrad current Iter:  90  Total Cost:  1.8258268795380304\n",
            "-------------------------\n",
            "e. Adadelta current Iter:  0  Total Cost:  14.772095264328314\n",
            "e. Adadelta current Iter:  10  Total Cost:  16.00113491847159\n",
            "e. Adadelta current Iter:  20  Total Cost:  18.05759997923358\n",
            "e. Adadelta current Iter:  30  Total Cost:  24.532368690260803\n",
            "e. Adadelta current Iter:  40  Total Cost:  24.602295298355983\n",
            "e. Adadelta current Iter:  50  Total Cost:  24.958219702345144\n",
            "e. Adadelta current Iter:  60  Total Cost:  24.99843329173483\n",
            "e. Adadelta current Iter:  70  Total Cost:  24.99915650183298\n",
            "e. Adadelta current Iter:  80  Total Cost:  24.99945264567687\n",
            "e. Adadelta current Iter:  90  Total Cost:  24.999557756692642\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------------\n",
            "f. RMSprop current Iter:  0  Total Cost:  6.5101857789552735\n",
            "f. RMSprop current Iter:  10  Total Cost:  1.7557278016671227\n",
            "f. RMSprop current Iter:  20  Total Cost:  0.5441184619320545\n",
            "f. RMSprop current Iter:  30  Total Cost:  0.011317952531789712\n",
            "f. RMSprop current Iter:  40  Total Cost:  0.0003363486824166213\n",
            "f. RMSprop current Iter:  50  Total Cost:  0.0001625564384211082\n",
            "f. RMSprop current Iter:  60  Total Cost:  0.00010938079271650851\n",
            "f. RMSprop current Iter:  70  Total Cost:  8.289092443889222e-05\n",
            "f. RMSprop current Iter:  80  Total Cost:  6.695395773814729e-05\n",
            "f. RMSprop current Iter:  90  Total Cost:  5.62507294253918e-05\n",
            "-------------------------\n",
            "g. Adam current Iter:  0  Total Cost:  5.594987618632648\n",
            "g. Adam current Iter:  10  Total Cost:  0.38296085909279975\n",
            "g. Adam current Iter:  20  Total Cost:  0.09956563998862818\n",
            "g. Adam current Iter:  30  Total Cost:  0.05269327671552893\n",
            "g. Adam current Iter:  40  Total Cost:  0.03150587107749636\n",
            "g. Adam current Iter:  50  Total Cost:  0.022329216909726342\n",
            "g. Adam current Iter:  60  Total Cost:  0.0164581979484879\n",
            "g. Adam current Iter:  70  Total Cost:  0.011767158661832136\n",
            "g. Adam current Iter:  80  Total Cost:  0.00715402994577244\n",
            "g. Adam current Iter:  90  Total Cost:  0.004334300603729487\n",
            "-------------------------\n",
            "h. Nadam current Iter:  0  Total Cost:  5.577196116405394\n",
            "h. Nadam current Iter:  10  Total Cost:  0.44282277401208076\n",
            "h. Nadam current Iter:  20  Total Cost:  0.11244773723799857\n",
            "h. Nadam current Iter:  30  Total Cost:  0.045640549560374145\n",
            "h. Nadam current Iter:  40  Total Cost:  0.03176485227546686\n",
            "h. Nadam current Iter:  50  Total Cost:  0.021366321212869913\n",
            "h. Nadam current Iter:  60  Total Cost:  0.012652281688069327\n",
            "h. Nadam current Iter:  70  Total Cost:  0.00957891780921108\n",
            "h. Nadam current Iter:  80  Total Cost:  0.00795000679508279\n",
            "h. Nadam current Iter:  90  Total Cost:  0.006388585592107601\n",
            "-------------------------\n",
            "i. SGD with Gaussian Noise current Iter:  0  Total Cost:  9.669279600516584\n",
            "i. SGD with Gaussian Noise current Iter:  10  Total Cost:  6.659940871327756\n",
            "i. SGD with Gaussian Noise current Iter:  20  Total Cost:  4.710895052490366\n",
            "i. SGD with Gaussian Noise current Iter:  30  Total Cost:  3.38460175334959\n",
            "i. SGD with Gaussian Noise current Iter:  40  Total Cost:  2.478275134490934\n",
            "i. SGD with Gaussian Noise current Iter:  50  Total Cost:  1.9201009390239245\n",
            "i. SGD with Gaussian Noise current Iter:  60  Total Cost:  1.5621687088841634\n",
            "i. SGD with Gaussian Noise current Iter:  70  Total Cost:  1.3013181242485832\n",
            "i. SGD with Gaussian Noise current Iter:  80  Total Cost:  1.1274982369010882\n",
            "i. SGD with Gaussian Noise current Iter:  90  Total Cost:  0.9890180639786231\n",
            "-------------------------\n",
            "j. noise current Iter:  0  Total Cost:  9.718282451030184\n",
            "j. noise current Iter:  10  Total Cost:  8.353775142378632\n",
            "j. noise current Iter:  20  Total Cost:  6.894195942444596\n",
            "j. noise current Iter:  30  Total Cost:  6.153468487335352\n",
            "j. noise current Iter:  40  Total Cost:  6.090381966691419\n",
            "j. noise current Iter:  50  Total Cost:  6.9704992999811894\n",
            "j. noise current Iter:  60  Total Cost:  7.594060503212478\n",
            "j. noise current Iter:  70  Total Cost:  8.289137080919014\n",
            "j. noise current Iter:  80  Total Cost:  8.749843690704294\n",
            "j. noise current Iter:  90  Total Cost:  8.953095931060306\n",
            "-------------------------\n",
            "k. noise Noise current Iter:  0  Total Cost:  9.72275349263023\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "k. noise Noise current Iter:  10  Total Cost:  8.373748543640446\n",
            "k. noise Noise current Iter:  20  Total Cost:  6.929437996152728\n",
            "k. noise Noise current Iter:  30  Total Cost:  6.172030131203154\n",
            "k. noise Noise current Iter:  40  Total Cost:  6.074822056044249\n",
            "k. noise Noise current Iter:  50  Total Cost:  7.000336010926327\n",
            "k. noise Noise current Iter:  60  Total Cost:  7.646323205397877\n",
            "k. noise Noise current Iter:  70  Total Cost:  8.318321514818278\n",
            "k. noise Noise current Iter:  80  Total Cost:  8.75680868739171\n",
            "k. noise Noise current Iter:  90  Total Cost:  8.953134913741838\n",
            "-------------------------\n",
            "l. noise adam current Iter:  0  Total Cost:  9.70228046352387\n",
            "l. noise adam current Iter:  10  Total Cost:  9.076893184509418\n",
            "l. noise adam current Iter:  20  Total Cost:  8.61712416780967\n",
            "l. noise adam current Iter:  30  Total Cost:  8.186853276259713\n",
            "l. noise adam current Iter:  40  Total Cost:  7.88507574730527\n",
            "l. noise adam current Iter:  50  Total Cost:  7.591419368888072\n",
            "l. noise adam current Iter:  60  Total Cost:  7.261430140792157\n",
            "l. noise adam current Iter:  70  Total Cost:  6.811772516478347\n",
            "l. noise adam current Iter:  80  Total Cost:  6.46453347789571\n",
            "l. noise adam current Iter:  90  Total Cost:  6.270818560832602\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAAFZCAYAAADZ6SWdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSCQTjBRfiUQikUgmGCm+EolEIpFMMP8fIYGhSSpj28UAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f586d63bb00>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}